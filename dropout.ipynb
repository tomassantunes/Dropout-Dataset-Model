{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação classe modelo\n",
    "\n",
    "#### pre_processing_data_average\n",
    "\n",
    "+ Os 2 atributos escolhidos serão a média dos creditos feitos por semestre e a média das notas de cada semestre\n",
    "  + Estes atributos foram escolhidos por ser os atributos que mais provavelmente irão afetar a \"Failure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelo:\n",
    "\n",
    "    # Remove id column (is not relevant in this case)\n",
    "    def pre_processing_data(data_train):\n",
    "        X = data_train.drop('Failure', axis=1).drop('Id', axis=1)\n",
    "        y = data_train.Failure\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def pre_processing_data_average(data_train):\n",
    "        classifications = data_train.drop('Failure', axis=1).drop('Id', axis=1).drop('Program', axis=1).drop(\n",
    "            list(data_train.filter(regex='enrol')), axis=1).drop(list(data_train.filter(regex='complete')), axis=1)\n",
    "        ects = data_train.drop('Failure', axis=1).drop('Id', axis=1).drop('Program', axis=1).drop(list(\n",
    "            data_train.filter(regex='enrol')), axis=1).drop(list(data_train.filter(regex='grade')), axis=1)\n",
    "\n",
    "        data_train['Classifications_mean'] = classifications.mean(axis=1)\n",
    "\n",
    "        data_train['ects'] = ects.mean(axis=1)\n",
    "\n",
    "        X = pd.concat([data_train.pop(x)\n",
    "                      for x in ['Classifications_mean', 'ects']], axis=1)\n",
    "        y = data_train.Failure\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def predict(X_train, X_test, y_train, y_test):\n",
    "        #model = DecisionTreeClassifier()\n",
    "        #model.fit(X_train, y_train)\n",
    "\n",
    "        # print prediction results\n",
    "        #predictions = model.predict(X_test)\n",
    "        #print(classification_report(y_test, predictions, zero_division=1))\n",
    "\n",
    "        # defining parameter range\n",
    "        # tira-mos 1 e 2 pois a cobertura da segunda parte era baixa\n",
    "        param_grid = {'max_depth': [4, 6, 8, 10],\n",
    "                      'min_samples_split': [2, 4, 6, 8, 10]}\n",
    "\n",
    "        grid = GridSearchCV(DecisionTreeClassifier(), param_grid,\n",
    "                            refit=True, verbose=0, n_jobs=-1)\n",
    "\n",
    "        # fitting the model for grid search\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "        # print best parameter after tuning\n",
    "        print(grid.best_params_)\n",
    "        grid_predictions = grid.predict(X_test)\n",
    "\n",
    "        # precision\n",
    "        print(\n",
    "            f\"Precisão: {precision_score(y_test, grid_predictions, average=None)[1]}\")\n",
    "\n",
    "        # Recall\n",
    "        print(\n",
    "            f\"Cobertura: {recall_score(y_test, grid_predictions, average=None)[1]}\")\n",
    "\n",
    "        # print classification report\n",
    "        print(classification_report(y_test, grid_predictions, zero_division=1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict do modelo, testes de precisão e cobertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_samples_split': 2}\n",
      "Precisão: 0.8363636363636363\n",
      "Cobertura: 0.8846153846153846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       318\n",
      "           1       0.84      0.88      0.86       104\n",
      "\n",
      "    accuracy                           0.93       422\n",
      "   macro avg       0.90      0.91      0.91       422\n",
      "weighted avg       0.93      0.93      0.93       422\n",
      "\n",
      "{'max_depth': 4, 'min_samples_split': 8}\n",
      "Precisão: 0.92\n",
      "Cobertura: 0.8846153846153846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       318\n",
      "           1       0.92      0.88      0.90       104\n",
      "\n",
      "    accuracy                           0.95       422\n",
      "   macro avg       0.94      0.93      0.94       422\n",
      "weighted avg       0.95      0.95      0.95       422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train = pd.read_csv(\"test-files/dropout-trabalho2.csv\")\n",
    "modelo = modelo\n",
    "\n",
    "# Primeira Parte\n",
    "X, y= modelo.pre_processing_data(data_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 1) \n",
    "modelo.predict(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Segunda parte\n",
    "X, y = modelo.pre_processing_data_average(data_train)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 1) \n",
    "modelo.predict(X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#load the dataset and split it into training and testing sets\n",
    "data_train = pd.read_csv(\"test-files/dropout-trabalho2.csv\")\n",
    "X = data_train.drop('Failure', axis=1)\n",
    "y = data_train.Failure\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.30, random_state = 1) \n",
    "# train the model on train set without using GridSearchCV \n",
    "model = SVC() \n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions, zero_division=1)) \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100],  \n",
    "    'gamma': [1, 0.1, 0.01],\n",
    "    'kernel': ['linear']}  \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearchCV using DecisionTrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#load the dataset and split it into training and testing sets\n",
    "data_train = pd.read_csv(\"test-files/dropout-trabalho2.csv\")\n",
    "X = data_train.drop('Failure', axis=1)\n",
    "y = data_train.Failure\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 1) \n",
    "# train the model on train set without using GridSearchCV \n",
    "model = DecisionTreeClassifier() \n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions, zero_division=1)) \n",
    "\n",
    "# defining parameter range \n",
    "param_grid = {'max_depth': [1, 2, 4, 6, 8, 10], 'min_samples_split': [2, 4, 6, 8, 10]}\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, refit = True, verbose = 3,n_jobs=-1) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "\n",
    "# print best parameter after tuning \n",
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification with DecisionTrees using the parameters given above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "#load the dataset and split it into training and testing sets\n",
    "data_train = pd.read_csv(\"test-files/dropout-trabalho2.csv\")\n",
    "X = data_train.drop('Failure', axis=1)\n",
    "y = data_train.Failure\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20, random_state = 1) \n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "model = DecisionTreeClassifier() \n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# print prediction results \n",
    "predictions = model.predict(X_test) \n",
    "print(classification_report(y_test, predictions, zero_division=1)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
